{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script trains and predicts the Gaussian naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.5.2\n",
      "keras version: 2.2.4-tf\n",
      "tensorflow version: 2.0.2\n",
      "matplotlib uses:  module://ipykernel.pylab.backend_inline\n",
      "No GPUs available\n"
     ]
    }
   ],
   "source": [
    "import vae_tools.sanity\n",
    "import vae_tools.viz\n",
    "import vae_tools.callbacks\n",
    "import vae_tools.loader\n",
    "from vae_tools.mmvae import MmVae, ReconstructionLoss\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "vae_tools.sanity.check()\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "# Set the seed for reproducible results\n",
    "import vae_tools.sampling\n",
    "vae_tools.sampling.set_seed(0)\n",
    "# resize the notebook if desired\n",
    "#vae_tools.nb_tools.notebook_resize()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the bayes classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def eval_bayes_classifier(z_train, z_test, y_train, y_test = None):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    # Train the GNB on the training data\n",
    "    gnb = GaussianNB().fit(z_train, y_train)\n",
    "    # Predict the test data using the GNB\n",
    "    y_pred_ab = gnb.predict(z_test['z_test_ab'])\n",
    "    y_pred_a = gnb.predict(z_test['z_test_a'])\n",
    "    y_pred_b = gnb.predict(z_test['z_test_b'])\n",
    "\n",
    "    if y_test is None:\n",
    "        print(\"Test on %d points.\" %(y_test.shape[0]))\n",
    "        print(\"mislabeled in ab : %d\" % ((y_test != y_pred_ab).sum()))\n",
    "        print(\"mislabeled in a  : %d\" % ((y_test != y_pred_a).sum()))\n",
    "        print(\"mislabeled in b  : %d\" % ((y_test != y_pred_b).sum()))\n",
    "\n",
    "    return y_pred_ab, y_pred_a, y_pred_b\n",
    "\n",
    "# Get the models and predict all data\n",
    "def predict(model_path, x_train = None, x_test = None):\n",
    "    num_models = 2\n",
    "    model_enc, _ = vae_tools.vae.GenericVae.load_model_powerset(model_path, num_models)\n",
    "    model_enc_a, model_enc_b, model_enc_ab = model_enc[0], model_enc[1], model_enc[2]\n",
    "    z_train, z_test = None, None\n",
    "    if x_train is not None:\n",
    "        z_train_ab = model_enc_ab.predict(x_train)\n",
    "        z_train_a = model_enc_a.predict(x_train[0])\n",
    "        z_train_b = model_enc_b.predict(x_train[1])\n",
    "        z_train = (z_train_a, z_train_b, z_train_ab)\n",
    "    if x_test is not None:\n",
    "        z_test_ab = model_enc_ab.predict(x_test)\n",
    "        z_test_a = model_enc_a.predict(x_test[0])\n",
    "        z_test_b = model_enc_b.predict(x_test[1])\n",
    "        z_test = (z_test_a, z_test_b, z_test_ab)\n",
    "    # Cleanup\n",
    "    for m in model_enc:\n",
    "        del m\n",
    "    tf.keras.backend.clear_session()\n",
    "    return z_train, z_test\n",
    "\n",
    "def run(seed = '0'):\n",
    "    (x_train_a, x_train_b), (x_test_a, x_test_b), y_train, y_test = vae_tools.loader.mnist_split(flatten = True, split = 'hor')\n",
    "    dump_loc = '/mnt/ssd_pcie/mmvae_mnist_split/' + seed + '/'\n",
    "    import time\n",
    "    # Process all 60 hyper parameter configurations\n",
    "    for idx in range(60):\n",
    "        start = time.time()\n",
    "        z_train_mean, z_test_mean = predict(dump_loc + 'enc_mean_' + str(idx) + '_ab_', x_train = [x_train_a, x_train_b], x_test = [x_test_a, x_test_b])\n",
    "        #z_train_logvar, z_test_logvar = predict(dump_loc + 'enc_logvar_' + str(idx) + '_ab_', x_train = [x_train_a, x_train_b], x_test = [x_test_a, x_test_b])\n",
    "\n",
    "        z_train_a, z_train_b, z_train_ab = z_train_mean[0], z_train_mean[1], z_train_mean[2]\n",
    "        z_test_a, z_test_b, z_test_ab = z_test_mean[0], z_test_mean[1], z_test_mean[2]\n",
    "\n",
    "        #z_train_logvar_a, z_train_logvar_b, z_train_logvar_ab = z_train_logvar[0], z_train_mean[1], z_train_logvar[2]\n",
    "        #z_test_logvar_a, z_test_logvar_b, z_test_logvar_ab = z_test_logvar[0], z_test_logvar[1], z_test_logvar[2]\n",
    "\n",
    "        z_test_all = {'z_test_ab': z_test_ab, 'z_test_a': z_test_a, 'z_test_b': z_test_b}\n",
    "\n",
    "        y_pred_ab_ab, y_pred_ab_a, y_pred_ab_b = eval_bayes_classifier(z_train_ab,\n",
    "                          z_test_all,\n",
    "                          y_train)\n",
    "\n",
    "        y_pred_a_ab, y_pred_a_a, y_pred_a_b = eval_bayes_classifier(z_train_a,\n",
    "                          z_test_all,\n",
    "                          y_train)\n",
    "\n",
    "        y_pred_b_ab, y_pred_b_a, y_pred_b_b = eval_bayes_classifier(z_train_b,\n",
    "                          z_test_all,\n",
    "                          y_train)\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "\n",
    "        # Store with scheme: <trained on dataset>_<validated on dataset>\n",
    "        y_pred = {'ab_ab': y_pred_ab_ab,\n",
    "        'ab_a': y_pred_ab_a,\n",
    "        'ab_b': y_pred_ab_b,\n",
    "        'a_ab': y_pred_a_ab,\n",
    "        'a_a':  y_pred_a_a,\n",
    "        'a_b':  y_pred_a_b,\n",
    "        'b_ab': y_pred_b_ab,\n",
    "        'b_a':  y_pred_b_a,\n",
    "        'b_b':  y_pred_b_b}\n",
    "\n",
    "        fn = dump_loc + 'bayes_classifier_' + str(idx) + '.p'\n",
    "        print(\"write \" + fn)\n",
    "        with open(fn, 'wb') as handle:\n",
    "            pickle.dump(y_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-24627164",
   "language": "python",
   "display_name": "PyCharm (vae_tools)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 987,
   "position": {
    "height": "40px",
    "left": "1273.52px",
    "right": "20px",
    "top": "255.75px",
    "width": "600px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}